# Model configuration for U-Net mel spectrogram reconstruction with Non-Local blocks

# Data settings
data:
  bin_dir: datasets
  bin_file: mel_spectrograms.h5
  data_key: mel_spectrograms  # Key for mel spectrograms in H5 file
  lazy_load: true             # Use lazy loading for H5 data
  phone_map:                  # Will be populated by preprocess.py
  raw_dir: datasets/gin
  # Dataset subset settings
  max_samples: 10           # Maximum number of samples to use (takes precedence over sample_percentage)
  sample_percentage: null     # Percentage of dataset to use (0.0-1.0)
  
# Audio settings
audio:
  sample_rate: 22050  # Default sample rate for audio processing
  n_fft: 1024         # FFT size
  hop_length: 256     # Hop length for the STFT
  win_length: 1024    # Window length for the STFT
  n_mels: 80          # Number of mel bands
  fmin: 0             # Minimum frequency for mel spectrogram
  fmax: 8000          # Maximum frequency for mel spectrogram
  f0_min: 50          # Minimum F0 frequency in Hz
  f0_max: 600         # Maximum F0 frequency in Hz
  plots_dir: logs/preprocess/plots    # Directory to save visualization plots

# Model settings
model:
  # Input/output dimensions
  time_frames: 128
  mel_bins: 80
  
  # Network scaling settings
  scale_factor: 1    # Width scaling (channel dimensions)
  layer_count: 4       # Depth scaling (number of encoder/decoder layer pairs)
  
  # U-Net architecture (base channel dimensions before scaling)
  encoder_channels: [16, 32, 64, 128]
  bottleneck_channels: 256
  decoder_channels: [64, 32, 16, 1]
  
  # Non-Local Block settings
  nl_blocks:
    use_nl_blocks: true       # Enable Non-Local blocks
    nl_in_bottleneck: true    # Add Non-Local block to bottleneck
    nl_mode: "embedded"       # Mode for Non-Local blocks ('gaussian', 'embedded', 'dot', 'concatenation')
    nl_encoder_layers: [-1]   # Indices of encoder layers to add NL blocks (-1 = last layer)
    nl_decoder_layers: [0]    # Indices of decoder layers to add NL blocks (0 = first layer)
    nl_reduction_ratio: 1     # Channel reduction ratio for efficiency
    nl_use_sub_sample: false   # Whether to use sub-sampling in NL blocks
  
  # Loss function weights
  loss_alpha: 0.8  # Weight for L1 loss
  loss_beta: 0.2   # Weight for Spectral Convergence loss

# Training settings
train:
  batch_size: 1
  num_epochs: 1000
  learning_rate: 0.001    #0.0008 # Slightly lower learning rate for stability with NL blocks
  weight_decay: 0.0001
  lr_scheduler: reduce_on_plateau
  lr_patience: 10
  lr_factor: 0.8
  validation_split: 0.1
  log_interval: 100
  save_interval: 100
  save_dir: logs/unet_nl
  
  # Hardware
  num_workers: 4
  pin_memory: true
  
# Validation settings
validation:
  val_every_epoch: 10
  max_samples: 4  # Maximum number of samples to visualize